{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying to impliment the espcn paper (paper number 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology:\n",
    "1. convoloving the filter as usual on the images with relu activation. (test with tanh)\n",
    "2. before passing it to ANNs we apply a sub-pixel layer \n",
    "3. pass the network in the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laoding the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_diff_multiscale(nn.Module):\n",
    "    def __init__(self, scale_factor=2):\n",
    "        super(CNN_diff_multiscale, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "        # Main branch\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, padding=9//2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, padding=3//2)\n",
    "        self.conv3 = nn.Conv2d(32, 16, kernel_size=3, padding=3//2)\n",
    "\n",
    "        # Parallel branch with larger receptive field\n",
    "        self.conv_large = nn.Conv2d(1, 32, kernel_size=13, padding=13//2)\n",
    "\n",
    "        # Upsampling layers\n",
    "        self.upsample = nn.PixelShuffle(self.scale_factor)\n",
    "        \n",
    "        # Final convolution\n",
    "        self.conv_final = nn.Conv2d(16 + 32 // (self.scale_factor ** 2), 1, kernel_size=5, padding=5//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch\n",
    "        main = F.relu(self.conv1(x))\n",
    "        main = F.relu(self.conv2(main))\n",
    "        main = F.relu(self.conv3(main))\n",
    "\n",
    "        # Parallel branch\n",
    "        large = F.relu(self.conv_large(x))\n",
    "\n",
    "        # Upsample both branches\n",
    "        main_up = self.upsample(main)\n",
    "        large_up = self.upsample(large)\n",
    "\n",
    "        # Concatenate upsampled features\n",
    "        combined = torch.cat([main_up, large_up], dim=1)\n",
    "\n",
    "        # Final convolution\n",
    "        output = self.conv_final(combined)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def multi_scale_loss(pred, target, scale_weights=[1.0, 0.5, 0.25]):\n",
    "        losses = []\n",
    "        for i, weight in enumerate(scale_weights):\n",
    "            if i > 0:\n",
    "                pred = F.interpolate(pred, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "                target = F.interpolate(target, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "            losses.append(weight * F.mse_loss(pred, target))\n",
    "        return sum(losses)\n",
    "    def random_scale_augmentation(image, min_scale=0.5, max_scale=2.0):\n",
    "        scale = random.uniform(min_scale, max_scale)\n",
    "        return F.interpolate(image, scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "\n",
    "# During training\n",
    "augmented_input = random_scale_augmentation(original_input)\n",
    "output = model(augmented_input)\n",
    "loss = multi_scale_loss(output, original_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
